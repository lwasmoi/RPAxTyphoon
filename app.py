import streamlit as st
import time
import re 
import uuid  
from openai import OpenAI
import config
from src import data_loader, embedding, rag_engine
from langsmith.wrappers import wrap_openai
from langsmith import traceable


# SETUP PAGE & SESSION 

st.set_page_config(
    page_title="‡∏ô‡πâ‡∏≠‡∏á‡∏ó‡∏∏‡∏ô AI",
    page_icon="ü§ñ",
    layout="centered", 
    initial_sidebar_state="collapsed", 
)
hide_streamlit_style = """
<style>
    /* ‡∏ã‡πà‡∏≠‡∏ô‡∏õ‡∏∏‡πà‡∏° 3 ‡∏à‡∏∏‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤‡∏ö‡∏ô (Hamburger Menu) */
    #MainMenu {visibility: hidden;}
    
    /* ‡∏ã‡πà‡∏≠‡∏ô‡πÅ‡∏ñ‡∏ö‡∏™‡∏µ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏™‡∏∏‡∏î (Header) */
    header {visibility: hidden;}
    
    /* ‡∏ã‡πà‡∏≠‡∏ô Footer ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á (Make with Streamlit) */
    footer {visibility: hidden;}
    
    /* (‡πÅ‡∏ñ‡∏°) ‡∏ã‡πà‡∏≠‡∏ô‡∏õ‡∏∏‡πà‡∏° Deploy ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ */
    .stDeployButton {display:none;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

@st.dialog("‡∏Ç‡πâ‡∏≠‡∏ï‡∏Å‡∏•‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
def show_disclaimer():
    st.markdown("""
        <style>
            /* ‡∏ã‡πà‡∏≠‡∏ô‡∏õ‡∏∏‡πà‡∏°  X ‡πÉ‡∏ô  */
            button[aria-label="Close"] {
                display: none !important;
            }
            /* ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏¥‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏µ‡∏î‡∏≥‡∏£‡∏≠‡∏ö‡∏ô‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏¥‡∏î (Overlay) */
            div[data-testid="stModal"] {
                pointer-events: none;
            }
            /* ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡∏Ñ‡∏•‡∏¥‡∏Å‡πÑ‡∏î‡πâ‡∏õ‡∏Å‡∏ï‡∏¥ */
            div[data-testid="stModal"] > div {
                pointer-events: auto;
            }
        </style>
        """, unsafe_allow_html=True)
    st.write("‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô AI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
    st.warning("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å AI ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏â‡∏ö‡∏±‡∏ö‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
    
    button_placeholder = st.empty()

    if "disclaimer_timer_done" not in st.session_state:
        for i in range(5, 0, -1):
            button_placeholder.button(f"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç... ({i})", disabled=True, key=f"wait_{i}")
            time.sleep(1)
        
        st.session_state.disclaimer_timer_done = True
        st.rerun()
        
    else:
        if button_placeholder.button("‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç", type="primary", key="accept_btn"):
            st.session_state.accepted_terms = True
            st.rerun()

if "accepted_terms" not in st.session_state:
    show_disclaimer()
    

# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ session_id  ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≠‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á
if "session_id" not in st.session_state:
    st.session_state.session_id = uuid.uuid4().hex[:4]

RETRIEVE_TOPK = 20
RERANK_TOPK = 8
TYPE_THRESH = {
    "fact": 0.38,           # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á/‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç 
    "definition": 0.36,     # ‡∏ô‡∏¥‡∏¢‡∏≤‡∏°‡∏®‡∏±‡∏û‡∏ó‡πå
    "troubleshoot": 0.34,   # ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ 
    "info": 0.35,           # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
    "guide": 0.35,          # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô/‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ 
    "warning": 0.36,        # ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô
    "contact": 0.37         # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠
}

def get_threshold(item_type: str) -> float:
    return TYPE_THRESH.get((item_type or "info").strip().lower(), 0.35)

def set_ask(txt):
    st.session_state.prompt_trigger = txt.replace("\n", " ")

@st.cache_resource(show_spinner="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•... ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà")
def setup_system():
    # Wrap OpenAI Client
    client = wrap_openai(OpenAI(api_key=config.CURRENT_KEY, base_url=config.CURRENT_URL))
    
    all_data = data_loader.load_supabase_knowledge()
    all_vecs = embedding.build_vector_store(all_data, config.CACHE_JSON)
    return client, all_data, all_vecs

try:
    client, all_data, all_vecs = setup_system()
except Exception as e:
    st.error(f"System Load Error: {e}"); st.stop()


@traceable(run_type="chain", name="Decision Logic")
def decide_log_sources(collected_data):
    final_sources = []
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ Debug ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö s3 ‡πÅ‡∏•‡∏∞ gap ‡πÉ‡∏´‡∏°‡πà
    debug_info = {
        "s1": 0, "s2": 0, "s3": 0,
        "gap_12": 0, "gap_23": 0,
        "decision": "No Data"
    }

    if collected_data:
        # ‡∏°‡∏µ‡πÅ‡∏Ñ‡πà 1 ‡∏≠‡∏±‡∏ô ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏•‡∏¢
        if len(collected_data) == 1:
            final_sources.append(collected_data[0][0])
            debug_info["s1"] = collected_data[0][1]
            debug_info["decision"] = "Single Item Found"
            
        # ‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏±‡∏ô
        else:
            s1 = collected_data[0][1] 
            s2 = collected_data[1][1] 
            gap_12 = s1 - s2
            debug_info["s1"] = s1
            debug_info["s2"] = s2
            debug_info["gap_12"] = gap_12

            if s1 >= 87.0 or gap_12 >= 8.0:
                final_sources.append(collected_data[0][0]) 
                debug_info["decision"] = "Dominant Win (Keep 1)"
            else:
    
                if len(collected_data) >= 3:
                    s3 = collected_data[2][1]
                    gap_23 = s2 - s3
                    
                    debug_info["s3"] = s3
                    debug_info["gap_23"] = gap_23
                    if gap_23 >= 5.0: 
                        final_sources = [d[0] for d in collected_data[:2]]
                        debug_info["decision"] = "Top 2 Separate (Keep 2)"
                    else:
                        final_sources = [d[0] for d in collected_data[:3]]
                        debug_info["decision"] = "Ambiguous (Keep 3)"
                
                else:
                    final_sources = [d[0] for d in collected_data[:2]]
                    debug_info["decision"] = "Only 2 Items (Keep 2)"
    
    log_string = ", ".join(final_sources) if final_sources else None
    return log_string, debug_info

# HEADER & RESET BUTTON

col_header, col_reset = st.columns([8, 2])

with col_reset:
    if st.button("‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà", type="primary", use_container_width=True):
        # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ 
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥..."): 
            time.sleep(1.0) 
            
        st.session_state.messages = []            
        st.session_state.session_id = uuid.uuid4().hex[:4] 
        st.rerun()                            

st.divider()



# CSS STYLING
st.markdown("""
<style>
    /* 1 ‡∏à‡∏±‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡∏´‡∏•‡∏±‡∏Å */
    .block-container { 
        max-width: 950px;
        padding-top: 2rem;
        padding-left: 2.5rem;
        margin: auto;
    }

    /* 2 ‡∏õ‡∏∏‡πà‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ */
    div.stButton > button {
        width: 220px; height: 70px;
        border-radius: 20px;
        padding: 0px 5px;
        display: flex; align-items: center; justify-content: center; text-align: center;
        line-height: 1.3; font-size: 16px; font-weight: 400;
        background: #ffffff; color: #1e293b; border: 1px solid #e2e8f0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        transition: transform 0.2s, box-shadow 0.2s;
    }
    div.stButton > button:hover {
        background: #f8fafc; border-color: #94a3b8; 
        transform: translateY(-4px); box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1); color: #0f172a;
    }

    /* 3 ‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏°‡∏ô‡∏π Popover */
    [data-testid="stPopover"] > button {
        height: 50px; min-height: 50px; width: auto; 
        border-radius: 25px; padding: 0 25px;
        background: #ffffff; border: none; color: #475569; font-weight: 600;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05); 
        display: inline-flex; justify-content: center;
    }
    [data-testid="stPopover"] > button:hover { color: #3b82f6; background: #f8fafc; }
    
    /* ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡∏≤‡∏ß‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö */
    [data-testid="stChatInput"] {
        border-radius: 30px !important; 
        background-color: #ffffff; 
        border: 1px solid #e2e8f0; 
        box-shadow: 0 6px 16px rgba(0, 0, 0, 0.08); 
        padding: 10px !important; /* ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏†‡∏≤‡∏¢‡πÉ‡∏ô */
    }

    /* ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏û‡∏¥‡∏°‡∏û‡πå */
    [data-testid="stChatInput"] textarea {
        font-size: 1.2rem !important;  /* ‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 19px) */
        line-height: 1.5 !important;
    }

    div.stButton > button[kind="primary"] {
        position: fixed !important;     
        top: 75px !important;           
        right: 45px !important;         
        z-index: 99999 !important;      
        
        /* ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ */
        font-size: 18px !important;      /* ‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÉ‡∏´‡∏ç‡πà */
        padding: 12px 24px !important;   /* ‡∏Ç‡∏≠‡∏ö‡∏õ‡∏∏‡πà‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô */
        font-weight: bold !important;
        
        background-color: #ffffff !important;
        color: #ef4444 !important;
        border: 2px solid #fee2e2 !important; /* ‡∏Ç‡∏≠‡∏ö‡∏´‡∏ô‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á */
        box-shadow: 0px 6px 12px rgba(0,0,0,0.1) !important;
        border-radius: 12px !important;
        width: auto !important;
        height: auto !important;
        margin-top: 0px !important;
    }
    
    div.stButton > button[kind="primary"]:hover {
        background-color: #fef2f2 !important;
        color: #b91c1c !important;
        border-color: #ef4444 !important;
        transform: scale(1.05) !important;
    }

    div[role="dialog"] button[kind="primary"],
    div[data-testid="stModal"] button[kind="primary"] {
        position: static !important;    
        top: auto !important;           
        right: auto !important;         
        z-index: 1 !important;          
        transform: none !important;     
        
        font-size: 16px !important;
        padding: 8px 16px !important;
        border: none !important;
        
        width: 100% !important;
        margin-top: 10px !important;
        background-color: #ff4b4b !important; 
        color: white !important;
        box-shadow: none !important;
    }
    
    div[role="dialog"] button[kind="primary"]:hover,
    div[data-testid="stModal"] button[kind="primary"]:hover {
        background-color: #ff3333 !important;
    }

    hr { display: none !important; }
    [data-testid="column"] { padding: 0 4px; }
</style>
""", unsafe_allow_html=True)


# CHAT DISPLAY & FEEDBACK
if "messages" not in st.session_state: st.session_state.messages = []
if "prompt_trigger" not in st.session_state: st.session_state.prompt_trigger = None

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á Assistant ‡πÅ‡∏•‡∏∞‡∏°‡∏µ log_id ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏∏‡πà‡∏°
        if msg["role"] == "assistant":
            log_id = msg.get("log_id")
            if log_id:
                feedback_key = f"fb_{log_id}"
                # ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏∏‡πà‡∏° (thumbs)
                score = st.feedback("thumbs", key=feedback_key)
                if score is not None:
                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á Database
                    data_loader.update_feedback(log_id, score)
                    feed_text = "Good" if score == 1 else "Bad"



# SUGGESTIONS & MENU


suggestions = [
    {"label": "‡∏Ç‡∏≠‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡πÄ‡∏ö‡∏¥‡∏Å‡πÄ‡∏á‡∏¥‡∏ô", "query": "‡∏Ç‡∏≠‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡πÄ‡∏ö‡∏¥‡∏Å‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏î‡∏£‡∏≠‡∏á‡∏à‡πà‡∏≤‡∏¢"},
    {"label": "‡∏Ç‡∏≠‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à", "query": "‡∏Ç‡∏≠‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å"},
    {"label": "‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ", "query": "‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ"},
    {"label": "‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏àRPA ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£", "query": "‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏àRPA ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£"}
]

if len(st.session_state.messages) == 0:
    st.markdown("<br><br>", unsafe_allow_html=True)
    st.markdown("<h4 style='text-align: center; color: #334155;'>‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</h4>", unsafe_allow_html=True)
    st.markdown("<br>", unsafe_allow_html=True)
    c1, c2, c3, c4 = st.columns(4, gap="small")
    cols = [c1, c2, c3, c4]
    for i, item in enumerate(suggestions):
        with cols[i]:
            st.button(item["label"], key=f"sug_full_{i}", on_click=set_ask, args=(item["query"],))
else:
    col_spacer, col_pop, col_rest = st.columns([0.2, 1.5, 8]) 
    with col_pop:
        with st.popover("‡πÄ‡∏°‡∏ô‡∏π‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°", use_container_width=True):
            st.markdown("###### ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠:")
            p_cols = st.columns(2)
            for i, item in enumerate(suggestions):
                p_cols[i % 2].button(item["label"], key=f"sug_pop_{i}", on_click=set_ask, args=(item["query"],))



# MAIN CHAT PROCESSING

chat_val = st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...")

if st.session_state.prompt_trigger:
    user_input = st.session_state.prompt_trigger
    st.session_state.prompt_trigger = None 
else:
    user_input = chat_val

if user_input:
    time.sleep(0.1)
    
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    rag_history = list(st.session_state.messages)[-3:]

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        log_source = None

        intent = rag_engine.analyze_intent(user_input)
        
        if intent == "BLOCK":
            full_response = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏ô‡πâ‡∏≠‡∏á‡∏ó‡∏∏‡∏ô‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ö‡∏¥‡∏Å‡∏à‡πà‡∏≤‡∏¢‡∏Ñ‡πà‡∏∞"
            message_placeholder.markdown(full_response)
        
        else:
            with st.status("‡∏ô‡πâ‡∏≠‡∏á‡∏ó‡∏∏‡∏ô‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î...", expanded=True) as status:
                st.write("‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°...")
                query = rag_engine.rewrite_query(user_input, rag_history, client, config.CURRENT_MODEL)
                st.write("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
                cands = rag_engine.retrieval_stage(query, all_data, all_vecs, top_k=RETRIEVE_TOPK)
                st.write("‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤...")
                results = rag_engine.reranking_stage(query, cands, top_k=RERANK_TOPK, intent=intent)

                context_lines = []
                pass_count = 0                
                collected_data = [] # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô tuple
                
                for item, score in results:
                    itype = (item.get("type") or "info").lower()
                    th = get_threshold(itype)
                    
                    if (score / 100.0) >= th:
                        pass_count += 1
                        context_lines.append(f"<{itype}>{item.get('content','')}</{itype}>")
                        
                        # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠ Source
                        src_name = item.get("metadata", {}).get("source")
                        if src_name:
                            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Ñ‡πà‡∏≠‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°
                            is_dup = any(d[0] == src_name for d in collected_data)
                            if not is_dup:
                                collected_data.append((src_name, score))
                

                log_source, debug_info = decide_log_sources(collected_data)
                
                context_str = "\n".join(context_lines).strip()
                has_context = (pass_count >= 1) and (len(context_str) > 0)
                status.update(label="‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô", state="complete", expanded=False)

            if not has_context:
                full_response = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Ñ‡πà‡∏∞ ‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ô‡∏π ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡πâ‡∏≤‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡πà‡∏∞"
                message_placeholder.markdown(full_response)
            else:
                msgs = [
                    {
                        "role": "system",
                        "content": f"{config.STATIC_SYS_PROMPT}\n\nContext from Database:\n{context_str}"
                    }
                ] + [{"role": "user", "content": query}]

                try:
                    stream = client.chat.completions.create(
                        model=config.CURRENT_MODEL,
                        messages=msgs, stream=True, temperature=0.3, max_tokens=4096,
                        extra_body={"repetition_penalty": 1.12, "top_p": 0.9}
                    )
                    for chunk in stream:
                        c = chunk.choices[0].delta.content
                        if c: 
                            if re.search(r'[\u4e00-\u9fff]', c):
                                continue 
                            full_response += c
                            message_placeholder.markdown(full_response + "‚ñå")
                    message_placeholder.markdown(full_response)
                except Exception as e:
                    st.error(f"Gen Error: {e}")
                    full_response = "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ñ‡πà‡∏∞"

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Log ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ session_id ‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏á‡∏ó‡∏µ‡πà
    saved_log_id = data_loader.save_chat_log(
        session_id=st.session_state.session_id,  
        user_input=user_input,
        ai_response=full_response,
        source=log_source
    )

    # ‡πÄ‡∏Å‡πá‡∏ö log_id ‡∏•‡∏á session
    st.session_state.messages.append({
        "role": "assistant", 
        "content": full_response,
        "log_id": saved_log_id  
    })
    
    st.rerun()